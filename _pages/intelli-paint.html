<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Intelli-Paint: Towards Developing More Human-Intelligible Painting Agents">
  <meta name="keywords" content="Intelli-Paint, Painting, ECCV 2022, Human-like, Interactive, Painting">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Intelli-Paint: Towards Developing More Human-Intelligible Painting Agents</title>

  <!-- Global site tag (gtag.js) - Google Analytics
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script> -->

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <!-- <link rel="icon" href="./static/images/favicon.svg"> -->
  <link href="/assets/images/icon.png" rel="icon" sizes="32x32" type="image/png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <base target="_blank">
</head>
<body>

<!-- Navigation bar for visiting other research pages -->
<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://1jsingh.github.io/">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://1jsingh.github.io/paint2pix">
            Paint2pix
          </a>
          <a class="navbar-item" href="https://1jsingh.github.io/intelli-paint">
            Intelli-paint
          </a>
          <a class="navbar-item" href="https://1jsingh.github.io/semantic-guidance">
            Semantic-Guidance
          </a>
        </div>
      </div>
    </div>

  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Intelli-Paint: Towards Developing More Human-Intelligible Painting Agents (ECCV 2022)</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://1jsingh.github.io/">Jaskirat Singh</a><sup>1,2</sup>,</span>
              <a href="#">Cameron Smith</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=AUsvKdEAAAAJ&hl=en">Jose Echevarria</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=vNHqr3oAAAAJ&hl=en">Liang Zheng</a><sup>1</sup>,</span>
            <span class="author-block">
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Australian National University,</span>
            <span class="author-block"><sup>2</sup>Adobe Research</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136760662.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2112.08930"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <span class="link-block">
                <a href="https://drive.google.com/file/d/1sf_kvdPcxU_w2e5ES-VAq_UsjN5i_TZA/view?usp=sharing"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://drive.google.com/file/d/1K_HZgJifUpZxDEqKyJHkU_FgPfOOKzGS/view?usp=sharing"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-scroll"></i>
                  </span>
                  <span>Poster</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="#"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Cite</span>
                  </a>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body" text-align: center>
      <img src="./docs/intelli-paint/assets/overview-v10.png" width=100%/>  
      <!-- <video id="teaser" autoplay muted loop playsinline height="100%">
        <source src="https://homes.cs.washington.edu/~kpar/nerfies/videos/teaser.mp4"
                type="video/mp4">
      </video> -->
      <h2 class="subtitle has-text-centered">
        We propose <em>Intelli-paint</em> which tries to address the need for more human-intelligible painting agents.  (Left) Painting sequence visualization which demonstrates that our method exhibits significantly higher resemblance with the human painting style as opposed to previous state of the art.  (Right) This resemblance is achieved through 1) a progressive layering strategy which allows for a more human-like evolution of the canvas, 2) a sequential attention mechanism which focuses on different image regions in a coarse-to-fine fashion and 3) a brushstroke regularization formulation which allows our method to obtain detailed results while using significantly fewer brushstrokes. 
        <!-- (~1/20 as compared to Paint Transformer in above). -->
      </h2>
    </div>
  </div>
</section>


<!-- <section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-steve">
          <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
            <source src="https://homes.cs.washington.edu/~kpar/nerfies/videos/steve.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="https://homes.cs.washington.edu/~kpar/nerfies/videos/chair-tp.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-shiba">
          <video poster="" id="shiba" autoplay controls muted loop playsinline height="100%">
            <source src="https://homes.cs.washington.edu/~kpar/nerfies/videos/shiba.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay controls muted loop playsinline height="100%">
            <source src="https://homes.cs.washington.edu/~kpar/nerfies/videos/fullbody.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-blueshirt">
          <video poster="" id="blueshirt" autoplay controls muted loop playsinline height="100%">
            <source src="https://homes.cs.washington.edu/~kpar/nerfies/videos/blueshirt.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-mask">
          <video poster="" id="mask" autoplay controls muted loop playsinline height="100%">
            <source src="https://homes.cs.washington.edu/~kpar/nerfies/videos/mask.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-coffee">
          <video poster="" id="coffee" autoplay controls muted loop playsinline height="100%">
            <source src="https://homes.cs.washington.edu/~kpar/nerfies/videos/coffee.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-toby">
          <video poster="" id="toby" autoplay controls muted loop playsinline height="100%">
            <source src="https://homes.cs.washington.edu/~kpar/nerfies/videos/toby2.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section> -->


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <!-- <iframe src="https://drive.google.com/file/d/1sf_kvdPcxU_w2e5ES-VAq_UsjN5i_TZA/preview" width="640" height="480" allow="autoplay"></iframe> -->
          <p>
            Stroke based rendering methods have recently become a popular solution for the generation of stylized paintings. However, the current research in this direction is focused mainly on the improvement of
            final canvas quality, and thus often fails to consider the intelligibility of
            the generated painting sequences to actual human users. In this work, we
            motivate the need to learn more human-intelligible painting sequences
            in order to facilitate the use of autonomous painting systems in a more
            interactive context (e.g. as a painting assistant tool for human users or
            for robotic painting applications). To this end, we propose a novel painting approach which learns to generate output canvases while exhibiting
            a painting style which is more relatable to human users. The proposed
            painting pipeline Intelli-Paint consists of 1) a progressive layering strategy which allows the agent to first paint a natural background scene
            before adding in each of the foreground objects in a progressive fashion.
            2) We also introduce a novel sequential brushstroke guidance strategy
            which helps the painting agent to shift its attention between different
            image regions in a semantic-aware manner. 3) Finally, we propose a
            brushstroke regularization strategy which allows for ~60-80% reduction
            in the total number of required brushstrokes without any perceivable
            differences in the quality of generated canvases. Through both quantitative and qualitative results, we show that the resulting agents not only
            show enhanced efficiency in output canvas generation but also exhibit
            a more natural-looking painting style which would better assist human
            users express their ideas through digital artwork.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Paper video. -->
    <!-- <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/MrKrnHhk8IA?rel=0&amp;showinfo=0"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div> -->
    <!--/ Paper video. -->
</section>

<!-- other sections -->
<section class="hero">
  <!-- Paper video. -->
  <div class="hero-body is-small">
  <div class="container alternate-section">
    <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-2">Need for more human-intelligible painting sequences?</h2>
          <p style="text-align:left">
            <b>Interactive Painting Applications</b>.  The practical merits of a stroke based rendering approach over pixel based image stylization methods (e.g. using GANs, VAEs) relies on its ability to mimic the human artistic creation process. Infact, several previous works including Paint Transformer, Optim and RL describe this ability to mimic a human-like painting process as their motivation for using a brushstroke based approach for image generation. The idea is that once trained, the learned painting agent can then act as a painting assistant / teaching tool for human users (Paint Transformer, RL {Huang <em>et al.</em>, 2019}). 
            <br><br>
            <b>Robotic Painting Applications</b>. Robotic applications for expression of AI creativity are being increasingly explored. For instance Pindar Van's cloudpainter robot has gained widespread global attention for the automated creation of artistic paintings. Our contribution is significant in this direction, as our method not only learns a painting sequence which is more interpretable to actual human users, but more importantly it provides an *efficient painting plan* which would allow a robotic agent to paint a vivid scene using significantly less number of total brushstrokes as compared to previous works. <br><br>
            <br>
          </p>
          <figure>
            <img src="./docs/intelli-paint/assets/prev_work_overview.png" width=100%/>
            <figcaption>Fig. 2 - Overview of the progressive gridding inference strategy from previous works. The painting agent  divides the overall image into successively finer grids, and then proceeds to paint each of them in parallel.</figcaption>
          </figure>
          <p style="text-align:left">
            <br><br>
            Despite the above mentioned motivations, the generation of competitive results using previous works is invariably dependent on a progressive grid-based division strategy. In this setting, the agent divides the overall image into successively finer grids, and then proceeds to paint each of them in parallel. Experimental analysis reveals that this not only reduces the efficiency of the final agent, but also leads to mechanical (grid-based) painting sequences (refer Fig. 2) which are not directly applicable to actual human users.
            <br><br> <br><br>
          </p>
          <figure align = "center"><img src="./docs/intelli-paint/assets/optim_grid_seq2.gif" alt="prev_work" width="350" height="256"> <figcaption align = "center"><br>Fig. 3 - Previous works exhibit a mechanical (grid-based) painting <br> sequence which is not directly applicable to human users. </figcaption></figure>
        </div>
    </div>
  </div>
  </div>
  
  <div class="hero-body is-small">
  <div class="container alternate-section">
    <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-2">Mimicking the human painting process</h2>
          <p style="text-align:left">
            In order to address the need for more human-intelligible painting sequences, we propose a novel <em>Intelli-Paint</em> pipeline which learns to paint canvases while mimicking the human painting process using three main modules. 
            <br><br>
          </p>
          <ol style="text-align:left">
            <li><strong><span>Progressive Layering</span></strong></li>
            <li><strong><span>Sequential Brushstroke Guidance</span></strong></li>
            <li><strong><span>Brushstroke Regularization</span></strong></li>
          </ol>
          <p style="text-align:left">
            <br>
            We next analyse the importance of each module in learning a more human-relatable painting style.
          </p>
        </div>
    </div>
  </div>
  </div>

  <div class="hero-body is-small">
    <div class="container alternate-section">
      <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <h2 class="title is-3">Progressive Layering</h2>
            <p style="text-align:left">
              The human painting process is often progressive and multi-layered. That is, instead of painting everything on the canvas at once, humans often first paint a basic background layer before progressively adding each of the foreground objects on top of it (refer Fig. 1). However, such a strategy is hard to learn using previous works which directly minimize the pixel wise distance the generated canvas and the target image.
              <br><br> 
              As shown in Fig. 4 below, we propose a progressive layering module, which much like a human artist, allows the painted canvas to evolve in multiple successive layers.
              <br><br> 
          </p>
            <figure align = "center">
              <img display=inline-block src="./docs/intelli-paint/assets/proglayer-test-1.gif" alt="Trulli" width="256" height="256"> 
              <img src="./docs/intelli-paint/assets/proglayer-test1-after.gif" alt="Trulli" width="256" height="256"> 
              </figure>
              <figure align = "center">
              <img display=inline-block src="./docs/intelli-paint/assets/proglayer-test-2.gif" alt="Trulli" width="256" height="256">
              <img src="./docs/intelli-paint/assets/proglayer-test2-after.gif" alt="Trulli" width="256" height="256">
              </figure>
              <figure align = "center">
              <img display=inline-block src="./docs/intelli-paint/assets/proglayer-test-3.gif" alt="Trulli" width="256" height="256"> 
              <img src="./docs/intelli-paint/assets/proglayer-test3-after.gif" alt="Trulli" width="256" height="256"> 
              </figure>
              <figure align = "center">
              <img display=inline-block src="./docs/intelli-paint/assets/proglayer-test-4.gif" alt="Trulli" width="256" height="256"> 
              <img src="./docs/intelli-paint/assets/proglayer-test4-after.gif" alt="Trulli" width="256" height="256"> 
              <figcaption align = "justify"><br>Fig. 4 - <b>Abalation analysis on role of progressive layering. </b> (<i>Left,Right</i>) Painting sequences w/o and with use of progressive layering.  Instead of starting to paint everthing on the canvas at once (left), the progressive layering approach (right) allows the painting agent to draw a given canvas in multiple layers (<i>e.g.</i> painting a realistic background layer before progressively adding foreground objects in above).</figcaption>
            </figure>
          </div>
      </div>
    </div>
    </div>

    <div class="hero-body is-small">
      <div class="container alternate-section">
        <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
              <h2 class="title is-3">Sequential Brushstroke Guidance</h2>
              <p style="text-align:left">
                Once the background layer has been painted, the sequential brush-stroke guidance strategy helps our method to add different foreground features in a semantic-aware manner.
                <br><br>
            </p>
            <figure align = "center">
              <img display=inline-block src="https://intellipaint.s3.us-west-1.amazonaws.com/project_website/seq_celeba1_seq.gif" alt="Trulli" width="256" height="256"> 
              <img src="https://intellipaint.s3.us-west-1.amazonaws.com/project_website/seq_celeba1.gif" alt="Trulli" width="256" height="256">
            </figure>
            <figure align = "center">
              <img display=inline-block src="https://intellipaint.s3.us-west-1.amazonaws.com/project_website/seq_celeba2.gif" alt="Trulli" width="256" height="256"> 
              <img src="https://intellipaint.s3.us-west-1.amazonaws.com/project_website/seq_celeba2_seq.gif" alt="Trulli" width="256" height="256"> 
              <figcaption align = "justify"><br>Fig. 5 - <b>Abalation analysis on role of sequential guidance. </b> (<i>Left,Right</i>) Painting sequences w/o and with use of sequential guidance after painting the  background layer.  Instead of adding brushstrokes randomly all over the canvas (left), our approach (right) constrains the painting agent to focus / refine different image areas in a coarse to fine semantic-aware manner.</figcaption></figure>
            </div>
        </div>
      </div>
      </div>

      <div class="hero-body is-small">
        <div class="container alternate-section">
          <div class="columns is-centered has-text-centered">
              <div class="column is-four-fifths">
                <h2 class="title is-3">Brushstroke Regularization</h2>
                <p style="text-align:left">
                  The current works on autonomous painting are often limited to using (an almost) fixed brush stroke budget irrespective of the complexity of the target image. Experiments reveal that this not reduces the efficiency of the generated painting sequence but also results in redundant / overlapping brushstroke patterns (refer Fig. 4) which impart an unnatural painting style to the final agent. As shown in Fig. 6 below, we propose a brushstroke regularization formulation which removes the above painting redundancies, thereby considerably improving both painting efficiency and human-relatability of our approach.                  
                  <br><br><br>
              </p>
              <figure align = "center">
                <img display=inline-block src="https://intellipaint.s3.us-west-1.amazonaws.com/project_website/strokereg_valley_before.gif" alt="Trulli" width="256" height="256"> 
                <img src="https://intellipaint.s3.us-west-1.amazonaws.com/project_website/strokereg_valley_after.gif" alt="Trulli" width="256" height="256"> 
                <figcaption align = "justify"><br>Fig. 6 - <b>Extreme ablation analysis on role of brushstroke regularization. </b> (<i>Left, Right</i>) Painting sequences before and after brushstroke regularization. The example on the left represents an extreme illustration of overlapping patterns occurring as a result of using a predetermined brushstroke budget (1000 brushstrokes) irrespective of the complexity of the target image (<i>e.g.</i> notice the unnatural way in which brushstrokes combine to form the final image). On right, we see how our brushstroke regularization formulation removes these rendundancies, which allows our method to paint a vivid scene in less than 100 brush strokes while exhibiting a more natural painting style.</figcaption>
              </figure>
              </div>
          </div>
        </div>
      </div>

      <div class="hero-body is-small">
        <div class="container alternate-section">
          <div class="columns is-centered has-text-centered">
              <div class="column is-four-fifths">
                <h2 class="title is-3">Painting Efficiency</h2>
                <!-- <p style="text-align:left">
                  <br><br><br>
                </p> -->
                <figure align = "center"><img src="./docs/intelli-paint/assets/paint_eff_qual3.png" alt="Trulli"> <figcaption align = "justify"><br>Fig. 7 - <b>Qualitative method comparison w.r.t. painting efficiency</b>  <i>(Left)</i> Comparing final canvas outputs while using ~ 300 brushstrokes for (b) Ours, (c) Paint Transformer, (d) Optim, (e) RL and (f) Semantic-RL. We observe that our approach results in more accurate depiction of the fine-grain features in the target image while using a low brushstroke count. </figcaption></figure>
              </div>
          </div>
        </div>
      </div>

      <div class="hero-body is-small">
        <div class="container alternate-section">
          <div class="columns is-centered has-text-centered">
              <div class="column is-four-fifths">
                <h2 class="title is-3">Resemblance with Human Painting Style</h2>
                <!-- <p style="text-align:left">
                  <br><br><br>
                </p> -->
                <figure align = "center"><img src="./docs/intelli-paint/assets/human_sim9.png" alt="Trulli"> <figcaption align = "justify"><br>Fig. 8 - <b>Qualitative method comparison w.r.t resemblance with the human painting style.</b>  We compare different methods (b-f). All painting sequences are generated using a different brushstroke count (indicated in the boxes), so as to ensure similar pixel-wise reconstruction loss with the target image. The corresponding frames for each sequence are computed after ~10%, 40%, 60% and 100% of the overall painting episode. We observe that our method offers higher resemblance with the human painting style (column-a) as compared to previous works.</figcaption></figure>              </div>
          </div>
        </div>
      </div>

      <div class="hero-body is-small">
        <div class="container alternate-section">
          <div class="columns is-centered has-text-centered">
              <div class="column is-four-fifths">
                <h2 class="title is-2">Conclusion</h2>
                <p style="text-align:left">
                  In this paper, we emphasize that the practical merits of an autonomous painting system should be evaluated not only by the quality of generated canvas but also by the interpretability of the corresponding painting sequence by actual human artists. To this end, we propose a novel <em>Intelli-Paint</em> pipeline which uses progressive layering to allow for a more human-like evolution of the painted canvas. The painting agent focuses on different image areas through a sequence of coarse-to-fine localized attention windows and is able to paint detailed scenes while using a limited number of brushstrokes. Experiments reveal that in comparison with previous state-of-the-art methods, our approach not only shows improved painting efficiency but also exhibits a painting style which is much more relatable to actual human users.  We hope our work opens new avenues for the further development of interactive and robotic painting applications in the real world.                  <br><br><br>
              </p>
              </div>
          </div>
        </div>
      </div>
</section>




<!-- Bibtex -->
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <span>If you find our work useful in your research, please cite the following works:</span> 
    <!-- <pre><code>@inproceedings{singh2022paint2pix,
      title={Paint2Pix: Interactive Painting based Progressive
            Image Synthesis and Editing},
      author={Singh, Jaskirat and Zheng, Liang and Smith, Cameron and Echevarria, Jose},
      booktitle={European conference on computer vision},
      year={2022},
      organization={Springer}
    }</code></pre> -->
    <pre><code>@inproceedings{singh2022intelli,
      title={Intelli-Paint: Towards Developing Human-like Painting Agents},
      author={Singh, Jaskirat and Smith, Cameron and Echevarria, Jose and Zheng, Liang},
      booktitle={European conference on computer vision},
      year={2022},
      organization={Springer}
    }</code></pre>
  </div>
</section>

</section>
<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="https://homes.cs.washington.edu/~kpar/nerfies/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            Website source code based on the <a
            href="https://github.com/nerfies/nerfies.github.io">Nerfies</a> project. If you want to reuse their source code, please credit them.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
